{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fi_VO8r3R1TT"
   },
   "source": [
    "# Analyzing A Movie Review Dataset[100 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gd1nFWBCP7GC"
   },
   "source": [
    "## 0. Text Preprocessing [10 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gaeN3k-w_ygu"
   },
   "source": [
    "Read through this tutorial on kaggle [here](\n",
    "https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words) , to\n",
    "familiarize yourself with its python tools and workflow. You'll have to download \"labeledTrainData.tsv\" and \"testData.tsv\" from [here](https://www.kaggle.com/c/word2vec-nlp-tutorial/data). Please remember to add your GT_UserName in the author function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IZAcFI1WbCc4",
    "outputId": "33b0e186-0bcb-4210-e15a-d6f90a59b4e0"
   },
   "outputs": [],
   "source": [
    "def author(gt_username = 'pbutler33'):\n",
    "    print(\"This assignment is submitted by {0}.\".format(gt_username))\n",
    "\n",
    "#Add your GT_UserName below and uncomment the line.\n",
    "#author()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UIpeJ8VmR1TX"
   },
   "outputs": [],
   "source": [
    "#Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import re\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from copy import deepcopy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CIvs0LVJR1Te"
   },
   "outputs": [],
   "source": [
    "# Reading in the data\n",
    "train = pd.read_csv(\"labeledTrainData.tsv\", delimiter=\"\\t\")\n",
    "test = pd.read_csv(\"testData.tsv\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ano1yq7oR1Th"
   },
   "outputs": [],
   "source": [
    "def preprocess_review(review):\n",
    "    \"\"\"Helper function to clean the reviews.\n",
    "\n",
    "     Arg: review: review text.\n",
    "     Returns: clean_review : Cleaned reviews\n",
    "\n",
    "     You should carry out the following steps.\n",
    "     1. Remove HTML Tags.\n",
    "     2. Remove non-letter characters.\n",
    "     3. Convert to lower case.\n",
    "     4. Remove stopwords.\n",
    "    \"\"\"\n",
    "\n",
    "    #Write your code below.\n",
    "    cleaned = BeautifulSoup(review).get_text()\n",
    "    cleaned = re.sub('[^a-zA-Z\\' ]', '', cleaned)\n",
    "    cleaned = cleaned.lower()\n",
    "    words = cleaned.split()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    clean_words = [w for w in words if w not in stop_words]\n",
    "    clean_review = \" \".join(clean_words)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    return clean_review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FJERbiU0R1Tj"
   },
   "outputs": [],
   "source": [
    "#Clean the reviews and add them to the list below\n",
    "cleaned_reviews = []\n",
    "\n",
    "#Write your code below.\n",
    "for r in train.review:\n",
    "    cleaned_reviews.append(preprocess_review(r))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dIq31H_fR1Tm"
   },
   "source": [
    "## 1. Processing Text to create Design Matrices [15 Points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "urCR0VMaR1Tn"
   },
   "outputs": [],
   "source": [
    "def design_matrix(cleaned_reviews):\n",
    "    \"\"\" Generate the 4 design matrices X_counts, X_binary, X_tfidf, X_binary_imbalance.\n",
    "\n",
    "      Args: cleaned_reviews: Cleaned Reviews.\n",
    "      Returns:\n",
    "            X_counts: Design Matrix X_counts.\n",
    "            X_binary: Design Matrix X_binary(Use the X_counts to generate this.)\n",
    "            X_tfidf:  Design Matrix X_tfidf\n",
    "            X_binary_imbalance: Design Matrix X_binary_imbalance(use fraction 0.75)\n",
    "            imbalance_train: Skewed training set(use fraction 0.75)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #Write your code here.\n",
    "    vectorizer = CountVectorizer(analyzer = \"word\",\n",
    "                                tokenizer = None,\n",
    "                                preprocessor = None,\n",
    "                                stop_words = None,\n",
    "                                max_features = 5000)\n",
    "    train_features = vectorizer.fit_transform(cleaned_reviews)\n",
    "    train_features = train_features.toarray()\n",
    "    X_counts = train_features\n",
    "    X_binary = X_counts > 0\n",
    "    X_binary=X_binary.astype('int')\n",
    "    X_tfidf = TfidfTransformer(smooth_idf = False).fit_transform(X_counts)\n",
    "    X_tfidf = X_tfidf.toarray()\n",
    "    np.random.seed(0)\n",
    "    drop_num = int(sum(train.sentiment) * 0.75)\n",
    "    idx = train[train.sentiment==1].index\n",
    "    drop_idx = np.random.choice(idx, drop_num)\n",
    "    X_binary_imbalance = X_counts.copy()\n",
    "    X_binary_imbalance = np.delete(X_binary_imbalance, drop_idx, axis=0)\n",
    "    imbalance_train = train.drop(drop_idx, axis=0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "  \n",
    "\n",
    "\n",
    "    return X_counts,X_binary,X_tfidf,X_binary_imbalance,imbalance_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_counts, X_binary, X_tfidf, X_binary_imbalance, imbalance_train = design_matrix(cleaned_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "POPvMtKER1Tp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5kt4EPPLR1Tx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xBH1DKHuR1T1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hcHBxl31R1T7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_binary_imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F5s2xUvMR1T-"
   },
   "source": [
    "## 2. Feature Space Similarity Experiment [25(5 + 5 + 15) Points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LRPAXIfDR1T_"
   },
   "outputs": [],
   "source": [
    "# Obtain the label on the original train set and imbalance train set\n",
    "train_sentiment = train[\"sentiment\"].values\n",
    "imbalance_train_sentiment = imbalance_train[\"sentiment\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rgK6cWOKUhIJ"
   },
   "outputs": [],
   "source": [
    "def dist(X, i, j, distance_function = \"euclidean\"):\n",
    "    \"\"\"The distance function returns the (Euclidean) distance between rows i and j of a design matrix.\n",
    "     Args: X : Design Matrix\n",
    "           i,j: row IDs\n",
    "           distance_function: The distance function to be used. Here we are using euclidean\n",
    "     Returns: The distance between row i and row j.\n",
    "  \n",
    "    \"\"\"\n",
    "    #Write your code here.\n",
    "    if distance_function == \"euclidean\":\n",
    "        distance =  np.linalg.norm(X[i]-X[j])\n",
    "    else:\n",
    "        distance = distance_function(X[i], X[j])\n",
    "    \n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cWvROZUqUnvJ"
   },
   "outputs": [],
   "source": [
    "def topk(X, k):\n",
    "    \"\"\"The topk(X, k) function returns ((i1,j1,d1),...(ik,jk,dk)) where (ix,jx) are the indices of the xth \n",
    "     closest pair, and dx is the corresponding distance. You can break ties randomly.\n",
    "     Args: X : Design Matrix\n",
    "           k:  Top k\n",
    "     Returns: top: A list of [row,col,distance]\n",
    "  \n",
    "    \"\"\"\n",
    "   \n",
    "    #Write your code here.\n",
    "    d_matrix = np.tril(pairwise_distances(X)) #lower triangular dist matrix\n",
    "    M = np.max(d_matrix)\n",
    "    d_matrix[d_matrix <= 0] = M #sets 0s to max so they dont interfere with finding closest pairs\n",
    "    low_idx = np.unravel_index(np.argpartition(d_matrix, axis=None, kth=k), d_matrix.shape)\n",
    "    top = tuple([(low_idx[0][i], low_idx[1][i], d_matrix[low_idx[0][i], low_idx[1][i]]) for i in range(k)])\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "            \n",
    "      \n",
    "    \n",
    "    \n",
    "    return top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z6QQdWA7BmMZ"
   },
   "source": [
    "Use topk() to find the closest review pairs for each design matrix and print the following: the indices of the reviews, the distance, the first 20 characters of each review, the labels for each review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L-pJSPn0a3NA",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pair 0\n",
      "Saw this in the thea\n",
      "Saw this in the thea\n",
      "pair 1\n",
      "Having the opportuni\n",
      "Having the opportuni\n"
     ]
    }
   ],
   "source": [
    "# compute top k for X_counts matrix and print the following: the indices of the reviews, the distance, the first 20 characters of each review, the labels for each review.\n",
    "#Write your code here.\n",
    "top_X_counts = topk(X_counts, 2)\n",
    "for i in range(2):\n",
    "    print('pair', i)\n",
    "    print(train.review[top_X_counts[i][0]][:20])\n",
    "    print(train.review[top_X_counts[i][1]][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TkvjeJMTaFTS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pair 0\n",
      "Saw this in the thea\n",
      "Saw this in the thea\n",
      "pair 1\n",
      "Having the opportuni\n",
      "Having the opportuni\n"
     ]
    }
   ],
   "source": [
    "# compute top k for X_binary matrix and print the following: the indices of the reviews, the distance, the first 20 characters of each review, the labels for each review.\n",
    "#Write your code here.\n",
    "top_X_bin = topk(X_binary, 2)\n",
    "for i in range(2):\n",
    "    print('pair', i)\n",
    "    print(train.review[top_X_bin[i][0]][:20])\n",
    "    print(train.review[top_X_bin[i][1]][:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OITNkuZUaOu_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pair 0\n",
      "Saw this in the thea\n",
      "Saw this in the thea\n",
      "pair 1\n",
      "Having the opportuni\n",
      "Having the opportuni\n"
     ]
    }
   ],
   "source": [
    "# compute top k for X_tfidf matrix and print the following: the indices of the reviews, the distance, the first 20 characters of each review, the labels for each review.\n",
    "#Write your code here.\n",
    "top_X_tfidf = topk(X_tfidf, 2)\n",
    "for i in range(2):\n",
    "    print('pair', i)\n",
    "    print(train.review[top_X_tfidf[i][0]][:20])\n",
    "    print(train.review[top_X_tfidf[i][1]][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ckNqY0ZbaU-z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pair 0\n",
      "Saw this in the thea\n",
      "Saw this in the thea\n",
      "pair 1\n",
      "Having the opportuni\n",
      "Having the opportuni\n"
     ]
    }
   ],
   "source": [
    "# compute top k for X_binary_imbalance matrix and print the following: the indices of the reviews, the distance, the first 20 characters of each review, the labels for each review.\n",
    "#Write your code here.\n",
    "top_X_imb = topk(X_binary_imbalance, 2)\n",
    "for i in range(2):\n",
    "    print('pair', i)\n",
    "    print(train.review[top_X_imb[i][0]][:20])\n",
    "    print(train.review[top_X_imb[i][1]][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ESA7ElrMbHEw"
   },
   "source": [
    "Are the pairs always the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yywNrWhlbQ10"
   },
   "source": [
    "## 3. Classification Experiment [35 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mo8UaxPjCr9Q"
   },
   "source": [
    "Now you’re going to tune an SVM classifier using each design matrix, and measure the\n",
    "resultant performance. Read the sklearn [docs](http://scikit-learn.org/stable/modules/cross_validation.html) on cross-validation to see the\n",
    "methods to use.\n",
    "*   Set your rng seed to 0 and create an initial learning_set / test_set split of 80-20.\n",
    "*   Now we want to use a linear SVM (svm.SVC with kernel=linear) and pick the best C value for our classifier.\n",
    "*   Repeat for each of the four design matrices:\n",
    "  *  Repeat 30 times:\n",
    "    *  Pick a random value of C uniformly in the interval (1e-4, 1e4).\n",
    "    *  Use 5-fold cross-validation to train the SVM.\n",
    "    *  Estimate and record the F1-Score.\n",
    "  *  Select the value of C which produced the best F1-Score and find out the F1-Score on the test set using that C.\n",
    "  *  Retrain the classifier using the entire learning set with this C value.\n",
    "  *  Submit test set predictions to Kaggle (see the section in the blog, and\n",
    "make sure you use their test data. You may need to retrain one more\n",
    "time using all “training data”). Print your Kaggle score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t9La4ICibWl6"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random as rd\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CD98GcZ9jJ2b"
   },
   "source": [
    "### 3.1 Utility Functions [10 (5 + 5) Points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N9K2mD7pe9Bc"
   },
   "outputs": [],
   "source": [
    "def calculateF1(X, y, k = 5):\n",
    "    \"\"\"calculateF1(X, y, k = 5) return two list which record all randomly selected c(in the interval (1e-4, 1e4))\n",
    "     and corresponding F1 scores.\n",
    "\n",
    "     Args: X: Features\n",
    "           y: Label of sentiment\n",
    "           k: Number of Cross-validation\n",
    "\n",
    "     Returns: c_list: List of all c values.\n",
    "              f1_list: Corresponding F1 Scores.\n",
    "    \"\"\"\n",
    "    rd.seed(0) #Setting a common seed\n",
    "\n",
    "    #Write your code here.\n",
    "    c_list = [0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1.0, 3.0, 10.0, 30.0, 100.0, 300.0, 1000.0, 3000.0, 10000]\n",
    "    #c_list = rd.uniform(0.0001, 10000, 30)\n",
    "    f1_list = []\n",
    "    for c in c_list:\n",
    "        mod = svm.LinearSVC(C = c)\n",
    "        f_scores = cross_val_score(mod, X, y, cv=k, scoring='f1')\n",
    "        f1_list.append(sum(f_scores)/5)\n",
    "        \n",
    "        \n",
    "    #I used the c-list above because it makes more sense to use evenly spaced values on a roughly logarithmic scale\n",
    "    #to hypertune the C parameter. If you want to run this code with the original instruction of sampling C values\n",
    "    #uniformly from the interval (0.0001, 10000), uncomment the code below the c_list definition and run that instead.\n",
    "    \n",
    "        \n",
    "    return c_list, f1_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ah82TDqCgKaN"
   },
   "outputs": [],
   "source": [
    "def findBestC(X, y, k = 5):\n",
    "    \"\"\"findBestC(X, y, k) return the best performance c, and the improvement(difference between best and worst f1_scores)/\n",
    "     Args: X: Features\n",
    "           y: Label of sentiment\n",
    "           k: Number of Cross-validation\n",
    "     Returns: c_best: C value with best f1_score.\n",
    "              improvement: difference between best and worst f1_score.\n",
    "    \"\"\"\n",
    "    #Write your code here.\n",
    "    c_vals, f_vals = calculateF1(X, y, k)\n",
    "    c_best = c_vals[np.argmax(f_vals)]\n",
    "    improvement = np.max(f_vals) - np.min(f_vals)\n",
    "    \n",
    "    return c_best,improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aAMZU6YBjUVU"
   },
   "source": [
    "### 3.2 Tune an SVM classifier using X_counts [20 (4*5) Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IVatM_PprZpC"
   },
   "source": [
    "#### 3.2.0 Utility Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AFjJKZKelYl5"
   },
   "outputs": [],
   "source": [
    "def findImprovement(X,train_sentiment,test_size = 0.2, random_state = 0):\n",
    "    \"\"\" Find the improvement in F1-Score of the design Matrix(X) using previous utility functions and the test_f1_score using the best C.\n",
    "\n",
    "      Args: X: Design Matrix\n",
    "            train_sentiment: Sentiments of the training data\n",
    "            test_size: Split it as 80:20\n",
    "            random_state: Seed\n",
    "\n",
    "      Returns:\n",
    "            c_best: The best possible c value\n",
    "            improvement: improvement in F1-Score using the design Matrix(X).\n",
    "            f1_s: Test F1 Score.\n",
    "            \n",
    "\n",
    "      You should carry out the following Steps:\n",
    "      1. Split the data using the above parameters.\n",
    "      2. Find out the best c and the improvement. (use 5-fold Cross Validation.)\n",
    "      3. Find out the test f1 score with this c.\n",
    "    \"\"\"\n",
    "    #Write your code here.\n",
    "    #Since we have a test set, I do not bother splitting X into train and test, instead I use the test data set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, train_sentiment, test_size = test_size, random_state = random_state)\n",
    "    c_best, improvement = findBestC(X_train, y_train)\n",
    "    final_mod = svm.LinearSVC(C=c_best).fit(X_train, y_train)\n",
    "    preds = final_mod.predict(X_test)\n",
    "    f1_s = f1_score(preds, y_test)\n",
    "\n",
    "    return c_best,improvement,f1_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f90fpHRiq1IM"
   },
   "source": [
    "#### 3.2.1 Tune an SVM classifier using X_counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vtON_6r5jgTL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05650875590079851 0.878185831828216\n"
     ]
    }
   ],
   "source": [
    "#Print the improvement using X_counts and the test f1_score using the best c.\n",
    "#Write your code here.\n",
    "c_best_counts, improvement_counts, f1_s_counts = findImprovement(X_counts, train.sentiment)\n",
    "print(improvement_counts, f1_s_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IygnGs8blBu-"
   },
   "outputs": [],
   "source": [
    "# Retrain the classifier using the entire learning set with c_best\n",
    "#Write your code here.\n",
    "counts_mod = svm.LinearSVC(C=c_best_counts).fit(X_counts, train.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IunoAYI6pgZW"
   },
   "source": [
    "Submit test set predictions to Kaggle (see the section in the blog, and\n",
    "make sure you use their test data. You may need to retrain one more\n",
    "time using all “training data”). Print your Kaggle scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9aRF1HA7lHAP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Kaggle Score using X_counts is 0.55523\n"
     ]
    }
   ],
   "source": [
    "#You should do the following steps.\n",
    "#1. Create bag of words from the test data.\n",
    "#2. Generate the labels using that test data.\n",
    "#3. Save the results to the pandas dataframe. For format check the blog.\n",
    "#4. Submit the results to Kaggle and add the scores here.\n",
    "\n",
    "#Write your code here.\n",
    "\n",
    "#Uncomment the below lines and add your score.\n",
    "test_reviews = []\n",
    "\n",
    "for r in test.review:\n",
    "    test_reviews.append(preprocess_review(r))\n",
    "    \n",
    "X_counts_test, X_binary_test, X_tfidf_test, X_binary_imbalance_test, imbalance_test = design_matrix(test_reviews)\n",
    "\n",
    "X_counts_preds = pd.DataFrame(columns = ['id', 'sentiment'])\n",
    "X_counts_preds.id = test.id\n",
    "X_counts_preds.sentiment = counts_mod.predict(X_counts_test)\n",
    "X_counts_preds.to_csv(\"X_counts_predictions\", index=False)\n",
    "X_counts_result = 0.55523\n",
    "print(\"The Kaggle Score using X_counts is {}\".format(X_counts_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cYRrpQtvrAKF"
   },
   "source": [
    "#### 3.2.2 Tune an SVM classifier using X_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jVwbgdUJrD5h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.056058941115158745 0.8702136235388956\n"
     ]
    }
   ],
   "source": [
    "#Print the improvement using X_binary and the test f1_score using the best c.\n",
    "#Write your code here.\n",
    "c_best_binary, improvement_binary, f1_s_binary = findImprovement(X_binary, train.sentiment)\n",
    "print(improvement_binary, f1_s_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hI0KVsQjsGHa"
   },
   "outputs": [],
   "source": [
    "# Retrain the classifier using the entire learning set with c_best\n",
    "#Write your code here.\n",
    "binary_mod = svm.LinearSVC(C=c_best_binary).fit(X_binary, train.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-zpgOR4NsdrP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Kaggle Score using X_binary is 0.54864\n"
     ]
    }
   ],
   "source": [
    "#Use the the same steps as you did for X_counts and print the kaggle score. Please note that you need to find X_binary_test using the X_counts_test.\n",
    "#Write your code here.\n",
    "X_binary_preds = pd.DataFrame(columns = ['id', 'sentiment'])\n",
    "X_binary_preds.id = test.id\n",
    "X_binary_preds.sentiment = binary_mod.predict(X_binary_test)\n",
    "X_binary_preds.to_csv(\"X_binary_predictions\", index=False)\n",
    "X_binary_result = 0.55652\n",
    "print(\"The Kaggle Score using X_binary is {}\".format(X_binary_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sRHMJO2os_tc"
   },
   "source": [
    "#### 3.2.3 Tune an SVM classifier using X_tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xnm8PdFWtGE9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07902993915283363 0.8866599799398196\n"
     ]
    }
   ],
   "source": [
    "#Print the improvement using X_tf_idf and the test f1_score using the best c.\n",
    "#Write your code here.\n",
    "c_best_tfidf, improvement_tfidf, f1_s_tfidf = findImprovement(X_tfidf, train.sentiment)\n",
    "print(improvement_tfidf, f1_s_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KWXXKrgGtU-r"
   },
   "outputs": [],
   "source": [
    "# Retrain svm using all X_tfidf data\n",
    "#Write your code here.\n",
    "tfidf_mod = svm.LinearSVC(C=c_best_tfidf).fit(X_tfidf, train.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "waBnpKAztX_H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Kaggle Score using X_tfidf is 0.54864\n"
     ]
    }
   ],
   "source": [
    "#Use the the same steps as you did for X_counts and print the kaggle score. Please note that you need to find X_tfidf_test using the X_counts_test.\n",
    "\n",
    "#Write your code here.\n",
    "\n",
    "X_tfidf_preds = pd.DataFrame(columns = ['id', 'sentiment'])\n",
    "X_tfidf_preds.id = test.id\n",
    "X_tfidf_preds.sentiment = counts_mod.predict(X_tfidf_test)\n",
    "X_tfidf_preds.to_csv(\"X_tfidf_predictions\", index=False)\n",
    "X_tfidf_result = 0.54432\n",
    "print(\"The Kaggle Score using X_tfidf is {}\".format(X_tfidf_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GSTHOCktwVf"
   },
   "source": [
    "#### 3.2.4 Tune an SVM classifier using X_binary_imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OWPad9EXtzKD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1915427513199064 0.7862242755144897\n"
     ]
    }
   ],
   "source": [
    "#Print the improvement using X_binary_imbalance and the test f1_score using the best c.\n",
    "#Write your code here.\n",
    "c_best_imbalance, improvement_imbalance, f1_s_imbalance = findImprovement(X_binary_imbalance, imbalance_train.sentiment)\n",
    "print(improvement_imbalance, f1_s_imbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oUsNuBpouEL-"
   },
   "outputs": [],
   "source": [
    "# Retrain svm using all X_binary_imbalance data.\n",
    "#Write your code here.\n",
    "imbalance_mod = svm.LinearSVC(C=c_best_imbalance).fit(X_binary_imbalance, imbalance_train.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a6YJvYHkuFh8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Kaggle Score using X_binary_imbalance is 0.55523\n"
     ]
    }
   ],
   "source": [
    "#Use the the same steps as you did for X_counts and print the kaggle score.\n",
    "\n",
    "#Write your code here.\n",
    "\n",
    "X_imbalance_preds = pd.DataFrame(columns = ['id', 'sentiment'])\n",
    "X_imbalance_preds.id = test.id\n",
    "X_imbalance_preds.sentiment = imbalance_mod.predict(X_counts_test)\n",
    "X_imbalance_preds.to_csv(\"X_imbalance_predictions\", index=False)\n",
    "X_imbalance_result = 0.55300\n",
    "print(\"The Kaggle Score using X_binary_imbalance is {}\".format(X_imbalance_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mRxZro0LMixK"
   },
   "source": [
    "Which design matrix performed best (e.g., which encoding method worked best)?\n",
    "What was the lift (improvement in F1-Score) between the worst and best cases for each experiment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DFjZq14Subsb"
   },
   "source": [
    "##4. Learning Curve Experiment [15(10 + 5) Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0LfArmX7M0-9"
   },
   "source": [
    "Using a logistic regression classifier and the design matrix X_counts, generate a learning curve:\n",
    "*  Set your rng seed to 0 and create an initial learning_set / test_set split of 80-20.\n",
    "*  Generate a learning curve (xval vs training error) for n=(100, 500, 1000, 2000,3000, 4000, 5000, 7500, 10000, 15000, 20000) training instances.\n",
    "*  Interpret the learning curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yZy1W2wCNRrU"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OQYNGVZYugpY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_instances = [100, 500, 1000, 2000, 3000, 4000, 5000, 7500, 10000, 15000, 20000]\n",
    "#Use the learning_curve module to generate mean train and test scores and plot them with X-axis being the number of training instances and Y-axis.\n",
    "#Please add appropriate title,labels and legends.\n",
    "#Write your code here.\n",
    "rd.seed(0)\n",
    "train_sizes, train_scores, test_scores = learning_curve(LogisticRegression(), X=X_counts, y=train.sentiment, train_sizes = training_instances, cv=5)\n",
    "train_avg = np.mean(train_scores, axis=1) #take row averages of train scores\n",
    "test_avg = np.mean(test_scores, axis=1) #take row averages of test scores\n",
    "plt.plot(train_sizes, train_avg, label='Training Accuracy')\n",
    "plt.plot(train_sizes, test_avg, label='Testing Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Accuracy vs. Training Size')\n",
    "plt.xlabel('Training Size')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xm0dRZbpScvV"
   },
   "source": [
    "##### Please provide an explanation to the nature of your graph in the above experiment."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW1_CSE_6240_template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
